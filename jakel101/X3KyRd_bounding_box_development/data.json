{
  "ver": "0.1",
  "info": {
    "id": "X3KyRd",
    "date": "1737245413",
    "viewed": 86,
    "name": "bounding box development",
    "username": "jakel101",
    "description": "trying to figure out how this would work (without looking it up)\n\nneeded for this unreleased one: https://www.shadertoy.com/view/lXycDz",
    "likes": 1,
    "published": 3,
    "flags": 0,
    "usePreview": 0,
    "tags": [
      "raytracing",
      "cube"
    ],
    "hasliked": 0,
    "retrieved": "2025-08-09T21:42:21.238037+00:00"
  },
  "renderpass": [
    {
      "inputs": [],
      "outputs": [
        {
          "id": 37,
          "channel": 0
        }
      ],
      "code": "// Apache 2.0 no patent (O)-(O)\n// working out: https://www.desmos.com/3d/dfrawfz5oy\n// improved: https://www.desmos.com/3d/loyr0cvm2c\n// done:? https://www.desmos.com/3d/bewjnaugsh\n# define PI 3.141592654\n# define FOV 90.0\n\nstruct Ray{\n    vec3 origin;\n    vec3 dir;\n    vec3 inv_dir; // for speedup?\n};\n\nstruct BoxHit{\n    bool hit;\n    bool inside;\n    vec3 entry;\n    vec3 exit;\n    vec3 entry_norm;\n    vec3 exit_norm;\n    float entry_dist;\n    float exit_dist;\n};\n\n// sorta reference: https://tavianator.com/2022/ray_box_boundary.html\nBoxHit AABB(vec3 center, vec3 size, Ray ray){\n    BoxHit res;\n        \n    vec3 pos = center + size;\n    vec3 neg = center - size;\n    \n    vec3 pos_dist = (pos-ray.origin) * ray.inv_dir;\n    vec3 neg_dist = (neg-ray.origin) * ray.inv_dir;\n    \n    vec3 min_dist = min(pos_dist, neg_dist);\n    vec3 max_dist = max(pos_dist, neg_dist);\n    \n    res.entry_dist = max(max(min_dist.x, min_dist.y), min_dist.z);\n    res.exit_dist = min(min(max_dist.x, max_dist.y), max_dist.z);\n    \n    // essentially methods?\n    res.hit = res.entry_dist < res.exit_dist && res.exit_dist > 0.0;\n    res.inside = res.entry_dist < 0.0; // entry behind us\n    \n    res.entry = ray.origin + ray.dir*res.entry_dist;\n    res.exit = ray.origin + ray.dir*res.exit_dist;\n    \n    // normals point away from the center\n    res.entry_norm = -sign(ray.dir) * vec3(greaterThanEqual(min_dist, vec3(res.entry_dist)));\n    res.exit_norm = sign(ray.dir) * vec3(lessThanEqual(max_dist, vec3(res.exit_dist)));\n    \n    return res;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // uv normalized to [-1..1] for height with more width\n    vec2 uv = (2.0*fragCoord - iResolution.xy)/iResolution.y;\n    vec2 mo = (2.0*iMouse.xy - iResolution.xy)/iResolution.y;\n    \n    //fragColor = texture(iChannel0, uv);\n    //return;\n    \n    // for when it's just idling...   \n    float azimuth = iTime*0.3 + mo.x; // keeps a bit of residue of the mouse!\n    float altitude = cos(iTime*0.5)*0.35;      \n    if (sign(iMouse.z) > 0.0){\n        // orbiting camera setup\n        azimuth = PI*mo.x;\n        altitude = 0.5*PI*clamp(mo.y, -0.85, 0.99); // maybe just positive?\n    }\n    \n    // make sure you don't look \"below\"\n    altitude = clamp(altitude, -PI, PI);\n    \n    // a unit length orbit!\n    vec3 camera_pos = vec3(\n        cos(azimuth)*cos(altitude),\n        sin(azimuth)*cos(altitude),\n        sin(altitude));               \n    // the camera is always looking \"at\" the origin or half way above it\n    vec3 look_dir = normalize(vec3(0.0, 0.0, 0.0) - camera_pos);\n    \n    \n    // TODO moving the camera in and out over time??\n    camera_pos += look_dir * -0.0; // moving the camera \"back\" to avoid occlusions?\n    // two vectors orthogonal to this camera direction (tagents?)    \n    //vec3 look_u = camera_pos + vec3(-sin(azimuth), cos(azimuth), 0.0);\n    //vec3 look_v = camera_pos + vec3(sin(altitude)*-cos(azimuth), sin(altitude)*-sin(azimuth), cos(altitude));    \n\n    \n    // turns out analytically these aren't correct. so using cross instead -.-\n    vec3 look_u = normalize(cross(vec3(0.0, 0.0, -1.0), look_dir));\n    vec3 look_v = normalize(cross(camera_pos, look_u)); // is this faster?\n    // camera plane(origin of each pixel) -> barycentric?\n    \n    vec3 camera_plane;\n    vec3 ray_dir;\n    vec3 ray_origin;\n                        \n    if (FOV > 0.0){\n        // assume a pinhole camera.\n        // FOV is the horizontal fov, the given focal length becomes:\n        // the 1.0 is the sensor height.\n        float focal_length = 1.0/tan(radians(FOV*0.5));\n        \n        // the ro\n        camera_plane = camera_pos - (look_dir*focal_length) + ((look_u*uv.x) + (look_v*uv.y))*-1.0; // inverted here to see upright\n        ray_origin = camera_pos;\n        \n        // the rd\n        ray_dir = camera_pos-camera_plane;\n        ray_dir = normalize(ray_dir);        \n    }\n    \n    else {\n        // negative FOV values are interpreted as a sensor size for a orthographic camera!\n        // horizontal sensor size, -1 would be something sensible... everything else is far away\n        float sensor_size = FOV*0.5*-1.0;\n        camera_plane = camera_pos + ((look_u*uv.x)+(look_v*uv.y))*sensor_size; // wider fov = larger \"sensor\"\n        ray_dir = look_dir;\n        ray_origin = camera_plane;\n    }\n    \n    \n    Ray camera = Ray(ray_origin, ray_dir, 1.0/ray_dir);\n    BoxHit res = AABB(vec3(0.0, sin(iTime*0.2), 0.0), vec3(0.5), camera);\n    \n    vec3 col = vec3(0.05);\n    \n    if (res.hit) {\n        col = res.entry_norm + vec3(0.5);\n        if (res.inside) {\n            //col = vec3(0.5);\n            col = res.exit_norm + vec3(0.5);\n        }\n    }\n    else {\n        //col = res.exit_norm + vec3(0.5);\n    }\n    \n    fragColor = vec4(col, 1.0);\n    \n}",
      "name": "Image",
      "description": "",
      "type": "image"
    }
  ]
}